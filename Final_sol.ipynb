{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74be00ca",
   "metadata": {},
   "source": [
    "## Final\n",
    "In this assignment you have difficult case when number of samples not bigger than number of dimensions. Here you should build classifier using train dataset, while test dataset is hidden. You can use any classifier from sklearn and transform features in any way too.\n",
    "\n",
    "Grading:\n",
    " - accuracy < 0.3 - no more than 5 pts\n",
    " - accuracy <= 0.35 - no more than 10 pts\n",
    " - accuracy <= 0.4 - no more than 15 pts\n",
    " - TOP 10 results - 30 points (maximum), others weighted amount of points between 30 and 20 points for those who get more than 0.40 according to difference between their score and worst score of TOP 10\n",
    " - accuracy >= 0.5 - at least 25 pts\n",
    " - accuracy >= 0.6 - at least 30 pts\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fe5f748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91cd841a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-7c06649c6c8c>:2: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_train = np.loadtxt('y_train', dtype=np.int)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((3072, 3072), (3072,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.loadtxt('X_train')\n",
    "y_train = np.loadtxt('y_train', dtype=np.int)\n",
    "\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae10b4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-70502171b33f>:2: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_test = np.loadtxt('y_test', dtype=np.int)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((3072, 3072), (3072,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = np.loadtxt('X_test')\n",
    "y_test = np.loadtxt('y_test', dtype=np.int)\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e64776c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the training and testing data are the same. So, I will take one of them and apply splitting to solve\n",
    "#the problem of overfitting.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test= train_test_split(X_train, y_train, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3123859",
   "metadata": {},
   "source": [
    "### Train part\n",
    "- implement feature transformation procedure in the function `transform_X(X)` if it is nedeed\n",
    "- you can use any classifier, just try to find good hyperparameters, name your result classifier `clf`\n",
    "- on the submition should be only 1 classifier in other case i can choose worst one\n",
    "\n",
    "don't forget about danger of overfitting to train data\n",
    "\n",
    "HERE baseline solution with SVM and with feature transformation that doesn't change anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fdd871c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01a928b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "def transform_X(X):\n",
    "    ## YOUR CODE FOR FEATURE TRANSFORMATION HERE\n",
    "    X = StandardScaler(with_mean=False).fit_transform(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e4856c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=transform_X(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7c4ca2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HERE JUST BASIC SOLUTION\n",
    "clf = SVC(kernel='rbf',C=10)\n",
    "clf.fit(transform_X(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53c1b3d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(transform_X(X_train))\n",
    "accuracy_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c4c40b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#param_grid = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001],'kernel': ['rbf', 'poly', 'sigmoid']}\n",
    "#svc= SVC()\n",
    "#model_svc = GridSearchCV(svc,param_grid)\n",
    "#model_svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "435ea8e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nparam_grid = {\\n    'bootstrap': [True],'max_depth': [20,30,40, 100, 110],\\n    'max_features': ['sqrt'],'min_samples_leaf': [5,10,15],\\n    'min_samples_split': [40,50,60], \\n    'n_estimators': [150, 200, 250]\\n}\\nrf = RandomForestClassifier()\\nmodel_rf = GridSearchCV(rf, param_grid=param_grid)\\n\\nmodel_rf.fit(X_train, y_train)\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "\"\"\"\n",
    "param_grid = {\n",
    "    'bootstrap': [True],'max_depth': [20,30,40, 100, 110],\n",
    "    'max_features': ['sqrt'],'min_samples_leaf': [5,10,15],\n",
    "    'min_samples_split': [40,50,60], \n",
    "    'n_estimators': [150, 200, 250]\n",
    "}\n",
    "rf = RandomForestClassifier()\n",
    "model_rf = GridSearchCV(rf, param_grid=param_grid)\n",
    "\n",
    "model_rf.fit(X_train, y_train)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17ff4ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#clf = RandomForestClassifier(max_depth=10)\n",
    "#clf.fit(transform_X(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ad4bddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#_pred = clf.predict(transform_X(X_train))\n",
    "#ccuracy_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2aa014ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "#from sklearn.metrics import accuracy_score\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#param_grid = { 'criterion':['gini','entropy'],'max_depth': np.arange(3, 15)}\n",
    "\n",
    "#tree=DecisionTreeClassifier()\n",
    "#model_tree= GridSearchCV(estimator = tree, param_grid = param_grid, cv=10)\n",
    "\n",
    "#model_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2738bec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "#clf = DecisionTreeClassifier(max_depth=10,criterion='entropy')\n",
    "#clf.fit(transform_X(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d43dea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = clf.predict(transform_X(X_train))\n",
    "#accuracy_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2af4b0f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom sklearn.linear_model import LogisticRegression\\n\\nparam_grid = {'penalty': ['l2'], 'C': [0.001,0.01,0.1,1,10,100,1000]}\\nlr = LogisticRegression(random_state=1,\\n                          solver='newton-cg',\\n                          multi_class='multinomial')\\nmodel_lr = GridSearchCV(lr, param_grid=param_grid)\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "param_grid = {'penalty': ['l2'], 'C': [0.001,0.01,0.1,1,10,100,1000]}\n",
    "lr = LogisticRegression(random_state=1,\n",
    "                          solver='newton-cg',\n",
    "                          multi_class='multinomial')\n",
    "model_lr = GridSearchCV(lr, param_grid=param_grid)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f58cc06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom sklearn.linear_model import LogisticRegression\\nclf = LogisticRegression(random_state=1,\\n                          solver='newton-cg',\\n                          multi_class='multinomial',\\n                        C=.001)\\nclf.fit(transform_X(X_train), y_train)\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=1,\n",
    "                          solver='newton-cg',\n",
    "                          multi_class='multinomial',\n",
    "                        C=.001)\n",
    "clf.fit(transform_X(X_train), y_train)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5c1a664",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = clf.predict(transform_X(X_train))\n",
    "#accuracy_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bbd2a5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.naive_bayes import GaussianNB\n",
    "#clf = GaussianNB()\n",
    "#clf.fit(transform_X(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "351129f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = clf.predict(transform_X(X_train))\n",
    "#accuracy_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dd84d7",
   "metadata": {},
   "source": [
    "### Test part, don't change anything here\n",
    "\n",
    "Here is used your `clf` trained before, at your folder **Test** and **Train** datasets are the same, but during grading differen **Test** dataset will be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5aa2e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test = np.loadtxt('X_test')\n",
    "#y_test = np.loadtxt('y_test', dtype=np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "84c35b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=transform_X(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "453e1082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4175704989154013"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using SVC\n",
    "y_pred = clf.predict(transform_X(X_test))\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "04ae6b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  the final  accuracy  using  SVC  is ≈ 42%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1287262",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
